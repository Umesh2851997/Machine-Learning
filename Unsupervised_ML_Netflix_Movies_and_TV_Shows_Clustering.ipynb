{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Umesh2851997/Machine-Learning/blob/main/Unsupervised_ML_Netflix_Movies_and_TV_Shows_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**   - Netflix Movies and TV Shows Clustering\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Umesh Makkar (Individual)"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.\n",
        "\n",
        "In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming serviceâ€™s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\n",
        "\n",
        "innitially we start with understanding the data set, then we clean the data to make analysis ready.\n",
        "\n",
        "explore the data and understand the behaviour of the same.\n",
        "\n",
        "we then prepare the data for creating clusters by various parameters wherein we remove stop words, white spaces numbers etc so that we can get important words and based on that we shall form clusters.\n",
        "\n",
        "later I have used the silhoute method and kmeans elbow method to find optimal number of clusters and built recommender system by cosine similarity and recommended top 5 movies."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix, as of 2022-Q2, stands as the foremost global provider of online streaming services, boasting a subscriber base exceeding 220 million. It is imperative for the platform to adeptly categorize its hosted shows to heighten user satisfaction and mitigate subscriber attrition.\n",
        "\n",
        "This project aims to discern similarities and differences among Netflix shows by creating clusters. These clusters can then be utilized to furnish users with personalized show recommendations aligned with their preferences.\n",
        "\n",
        "The primary objective is to categorize Netflix shows into distinct clusters, ensuring that shows within a cluster share similarities while those in separate clusters exhibit dissimilarity."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "# Numpy & Pandas for data processing & wrangling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Data Visulization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "\n",
        "#Importing libraries for hypothesis testing\n",
        "from scipy.stats import uniform #Uniform Distribution\n",
        "from scipy.stats import norm #Normal Distribution (Gaussian Distribution)\n",
        "from scipy.stats import chi2 #Chi-squared Distribution\n",
        "from scipy.stats import t #t Distribution\n",
        "from scipy.stats import f #f Distribution\n",
        "from scipy.stats import ttest_ind #independent two-sample t-test\n",
        "import scipy.stats as stats #Statistical Function\n",
        "\n",
        "# Clusters impelementation Libraries\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as shc\n",
        "\n",
        "# Building recommandation system\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import *\n",
        "import scipy.cluster.hierarchy as sch\n",
        "\n",
        "#Others Libraries\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "#font size throughout the notebook\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "# plt.rcParams['font.weight'] = 'bold'\n",
        "plt.rcParams['axes.titleweight'] = 'bold'"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/My_new_numpy/netflix_titles.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "hn5aH3e8eBDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "rc = df.shape\n",
        "print(f'This data set has {rc[0]} rows and {rc[1]} columns. ')"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate = df.duplicated().sum()\n",
        "print(f'this data set has {duplicate} duplicate')"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "missing_values = df.isna().sum()\n",
        "print(missing_values)\n",
        "print('-'*50)\n",
        "print('Missing values in Proportion')\n",
        "missing_percentages = (df.isna().mean() * 100).round(2)\n",
        "print(missing_percentages)"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "my_palette = sns.color_palette('Reds', 1)\n",
        "msno.bar(df,color = 'Red')\n",
        "#msno.heatmap(df, cmap=my_palette)\n",
        "plt.title('Visualizing the missing values')"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "show_id: Unique Id number for all the listed rows\n",
        "\n",
        "type: denotes type of show namely TV Show or Movie\n",
        "\n",
        "title: title of the movie\n",
        "\n",
        "director: Name of director/directors\n",
        "\n",
        "cast: lists the cast of the movie\n",
        "\n",
        "country: country of the production house\n",
        "\n",
        "date_added: the date the show was added\n",
        "\n",
        "release_year: year of the release of the show\n",
        "\n",
        "rating: show ratings\n",
        "\n",
        "duration: duration of the show\n",
        "\n",
        "listed_in: the genre of the show\n",
        "\n",
        "description: summary/ description of the movie"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include = 'all').T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "show_id: Unique Id number for all the listed rows\n",
        "\n",
        "type: denotes type of show namely TV Show or Movie\n",
        "\n",
        "title: title of the movie\n",
        "\n",
        "director: Name of director/directors\n",
        "\n",
        "cast: lists the cast of the movie\n",
        "\n",
        "country: country of the production house\n",
        "\n",
        "date_added: the date the show was added\n",
        "\n",
        "release_year: year of the release of the show\n",
        "\n",
        "rating: show ratings\n",
        "\n",
        "duration: duration of the show\n",
        "\n",
        "listed_in: the genre of the show\n",
        "\n",
        "description: summary/ description of the movie"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "goGmZFN4h6_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# filling cast value as not available\n",
        "df['cast'] = df['cast'].fillna(value='Not available')\n",
        "\n",
        "# filling contry null values as not known, the same can be replaced by mode of the country using the below commented code\n",
        "# Note: only one line should be selected to run this\n",
        "df['country'] = df['country'].fillna(value='Not Known')\n",
        "\n",
        "# since date_added and rating have low % share that is 0.13 and 0.09 we are dropping the same\n",
        "df = df.dropna(subset=['date_added','rating'])\n",
        "\n",
        "# Too many missing values in director column, we are dropping\n",
        "df = df.drop(['director'],axis=1)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=['duration'])"
      ],
      "metadata": {
        "id": "ITu6z7zbispS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "xIl8tUiLjrtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imputed missing values in the \"cast\" column with \"Not available.\"\n",
        "\n",
        "Imputed missing values in the \"cast\" column with \"Not Known.\"\n",
        "Removed rows with missing values in the \"date_added\"\n",
        "\n",
        "Removed rows with missing values in the \"ratings\"\n",
        "\n",
        "Dropped the entire \"director\" column, as it contained 30% missing data."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "type_counts = df['type'].value_counts()\n",
        "\n",
        "# Set the figure size\n",
        "plt.rcParams['figure.figsize'] = (5, 5)\n",
        "\n",
        "# Set the distance for displaying values inside the pie chart\n",
        "pct_distance = 0.9\n",
        "\n",
        "# Plot a pie chart with percentage labels\n",
        "type_counts.plot(kind='pie', autopct='%1.2f%%', pctdistance=pct_distance)\n",
        "\n",
        "# Set the title for the pie chart\n",
        "plt.title('Distribution of Movies and TV Shows')\n",
        "\n",
        "# Display the pie chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Easy to undertand & interpret the logic and share the percentage using PIE."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "69.05% of the data is of movies while 30.95% of the data belongs to TV Shows"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Set the figure size for the countplot\n",
        "plt.figure(figsize=(20, 5))\n",
        "\n",
        "# Create a countplot for the 'rating' column in the DataFrame\n",
        "sns.countplot(x='rating', data=df)\n",
        "\n",
        "# Set the title for the countplot\n",
        "plt.title('Distribution of Ratings')\n",
        "\n",
        "# Rotate x-axis labels for better readability\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Display the countplot\n",
        "plt.show()\n",
        "\n",
        "# Print the counts for reference\n",
        "print(\"Rating Counts:\\n\", df['rating'].value_counts())"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Countplot is easy to visualize the data."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is found that most of the ratings are given by TV-MA(2863) followed by TV-14(1931) the least ratings are by NC-17(3)"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Very good to understand the Rating system."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(20, 5))\n",
        "df['country'].value_counts().head(10).sort_values(ascending = True).plot(kind='barh')\n",
        "\n",
        "# setting chart title\n",
        "plt.title('Counts of production country')\n",
        "plt.xticks(rotation = 90)\n",
        "plt.ylabel('year')\n",
        "plt.xlabel('count')\n",
        "# displaying the  chart\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# printing the counts for reference\n",
        "print(df.country.value_counts().head(10))"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good to Visualize & Interpret the dat using this chart"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the content belongs to United States, followed by india."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data will be Useful to understand the country wise production."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "ZYWDNSvitURk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# creating temp dataframe\n",
        "temp_data_df = df.groupby(['release_year'])['show_id'].count()\n",
        "plt.rcParams['figure.figsize'] = (20, 5)\n",
        "\n",
        "# plotting the temp df\n",
        "temp_data_df.plot.line()\n",
        "# setting chart title\n",
        "plt.title('Counts of movies with respect to various years')\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Release Year')\n",
        "# display chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line chart is easy to show the trends over the period"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " we can see the count of movies between 1940 and 2000 then in next 20 year it jumped dramatically and then a quick down fall."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "most of the movies released are new or old, its found that most are from recently released"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tv_shows_df = df[df['type']=='TV Show']\n",
        "movies_df = df[df['type']=='Movie']"
      ],
      "metadata": {
        "id": "Ynmrwi3HArnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv_shows_df.head()"
      ],
      "metadata": {
        "id": "oN9zUr4OAtU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.head()"
      ],
      "metadata": {
        "id": "4WIHidpTAy_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "movie_ratings = movies_df.groupby(['rating'])['show_id'].count().reset_index(name='count').sort_values('count', ascending=False).reset_index()\n",
        "# top10_movies = movies_df['listed_in'].value_counts().reset_index(name='count').head(10)\n",
        "# print(top10_movies)\n",
        "sns.barplot(x='rating',y='count',data=movie_ratings)\n",
        "\n",
        "# setting chart title\n",
        "plt.title('Counts of movies with respect to various type of ratings')\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Ratings')\n",
        "# display chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "easy to show & interpret this chart   "
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count of Movies with respected type of Rating"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "tv_shows_ratings = tv_shows_df.groupby(['rating'])['show_id'].count().reset_index(name='count')\n",
        "tv_shows_ratings = tv_shows_ratings.sort_values('count', ascending=False).reset_index()\n",
        "\n",
        "sns.pointplot(x='rating',y='count',data=tv_shows_ratings)\n",
        "sns.boxplot(x='rating',y='count',data=tv_shows_ratings)\n",
        "\n",
        "# setting chart title\n",
        "plt.title('Counts of TV Shows with respect to various type of ratings')\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Ratings')\n",
        "# display chart\n",
        "plt.show()\n",
        "# print(tv_shows_ratings)\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " scatter plot is best to undersatnd how the data is scattered in the given trends."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is found that TV-MA rating is max that is 1016 for the TV Shows followed by 656 for TV-14 the least ratings are by TV-Y7-FV that is 1 and R is 2."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " understand the trends of ratings for TV showsAnswer Here"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# getting counts of different movies in listed in\n",
        "top10_movies = movies_df['listed_in'].value_counts()\n",
        "# sorting based on counts\n",
        "top10_movies = top10_movies.sort_values(ascending=True)\n",
        "# getting to 10 of the dataframe from bottom\n",
        "top10_movies = top10_movies.tail(10)\n",
        "\n",
        "# plotting\n",
        "top10_movies.plot(kind='barh')\n",
        "# setting chart title\n",
        "plt.title('Top 10 Movies Genre')\n",
        "plt.ylabel('Listed In')\n",
        "plt.xlabel('count')\n",
        "# display chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eaasy to Understand & Interpret"
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is found that there are 334 documentaries and 321 Standup comedy"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "understand the trends of movies Genre"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# getting counts of different TV shows in listed in\n",
        "top10_TV_Shows = tv_shows_df['listed_in'].value_counts()\n",
        "# sorting based on counts\n",
        "top10_TV_Shows = top10_TV_Shows.sort_values(ascending=True)\n",
        "# getting to 10 of the dataframe from bottom\n",
        "top10_TV_Shows = top10_TV_Shows.tail(10)\n",
        "\n",
        "# plotting\n",
        "top10_TV_Shows.plot(kind='barh')\n",
        "# setting chart title\n",
        "plt.title('Top 10 TV Shows Genre')\n",
        "plt.ylabel('Listed In')\n",
        "plt.xlabel('count')\n",
        "# display chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "sns.histplot(movies_df['duration'].str.extract('(\\d+)').astype(int), kde=True, color='red')\n",
        "\n",
        "# setting chart title\n",
        "plt.title('Hist plot for movies duration')\n",
        "plt.ylabel('count')\n",
        "plt.xlabel('Duration')\n",
        "# display chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Better way to show the distribution"
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see the Movie distribution in this given chart."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "sns.histplot(tv_shows_df['duration'].str.extract('(\\d+)').astype(int), kde=True, color='red')\n",
        "# setting chart title\n",
        "plt.title('Hist plot for TV Show duration')\n",
        "plt.ylabel('count')\n",
        "plt.xlabel('Duration')\n",
        "# display chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Better To understand the Distribution.  "
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the Tv show distribution."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "sns.countplot(x='release_year',hue='type', data=df)\n",
        "\n",
        "# setting chart title\n",
        "plt.title('Various types of shows released with respect to year')\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# display chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A seaborn count plot shows counts of TV Shows and Movies with respect to various years"
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trends of TV shows increased over time the moves relased after 2010 started to list on netflix trends increased"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trends of TV shows increased over time."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "corr_matrix = df.corr()\n",
        "plt.figure(figsize=(15,8))\n",
        "# Plot heatmap\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='cool')\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " corelation chart shows the relation between the two specific feature"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(df, diag_kind=\"kde\", kind = 'reg')\n",
        "\n",
        "\n",
        "#setting labels to infer the plot\n",
        "plt.title('Pair Plot')"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pair plots are used to show relationship between various variables\n",
        "\n",
        "Pair plots can also help us explore the distribution of variables in your dataset"
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there is only one value in dataframe of int type, we are unable to visualize the pair plot"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix has the highest number of content in the United States, followed by India. India has the highest number of movies on Netflix\n",
        "\n",
        "Null hypothesis H0: The average number of movies on Netflix in the United States is equal to the average number of movies on Netflix in India.\n",
        "\n",
        "Alternate hypothesis Ha: The average number of movies on Netflix in the United States is greater than the average number of movies on Netflix in India."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "us_movie_df = movies_df[movies_df.country == 'United States']\n",
        "india_movie_df = movies_df[movies_df.country == 'India']\n",
        "\n",
        "# Perform a two-sample t-test between the release years of the two groups of movies\n",
        "t, p = ttest_ind(us_movie_df['release_year'], india_movie_df['release_year'], equal_var=False)\n",
        "\n",
        "# Set the significance level to 0.05\n",
        "alpha = 0.05\n",
        "\n",
        "# Check if the calculated p-value is less than the significance level\n",
        "if p < alpha:\n",
        "  # If the p-value is less than the significance level, reject the null hypothesis\n",
        "  print(\"We reject the null hypothesis.\")\n",
        "else:\n",
        "  # If the p-value is greater than or equal to the significance level, fail to reject the null hypothesis\n",
        "  print(\"We fail to reject the null hypothesis.\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compare the number of movies available on Netflix in the United States and India, I conducted a two-sample t-test, also known as an independent samples t-test or unpaired t-test. I utilized the ttest_ind function from the scipy.stats module to carry out the test, which is suitable for analyzing the means of two independent samples. By applying this test, I was able to calculate the p-value and determine if there is a significant difference in the number of movies between the two countries."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected the two-sample t-test for this analysis as it is suitable for comparing the means of two independent samples. In this case, we have two separate sets of movie data from Netflix for the United States and India, and we aim to determine if there is a significant difference in the average number of movies between these two countries."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the countplot, it appears that Netflix adds the highest number of movies and TV shows during the period between October and January. This period seems to be the busiest time of year for Netflix in terms of adding new content to its platform.\n",
        "\n",
        "Null hypothesis H0: There is no significant difference in the number of movies and TV shows added by Netflix across different months.\n",
        "Alternate hypothesis Ha: There is a significant difference in the number of movies and TV shows added by Netflix across different months."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Convert the date_added column of the DataFrame to a datetime format\n",
        "df[\"date_added\"] = pd.to_datetime(df[\"date_added\"])\n",
        "\n",
        "# Extract the month name from the date_added column and create a new column\n",
        "df[\"month_added\"] = df[\"date_added\"].dt.month_name()\n",
        "\n",
        "# Create a contingency table of the type and month_added columns\n",
        "contingency_table = pd.crosstab(df[\"type\"], df[\"month_added\"])\n",
        "\n",
        "# Perform a chi-square test on the contingency table\n",
        "from scipy.stats import chi2_contingency\n",
        "chi2_statistic, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "# Rounding to 2\n",
        "chi2_statistic = round(chi2_statistic, 2)\n",
        "p_value = round(p_value, 2)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Chi-square statistic: {chi2_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(\"Expected Frequencies:\")\n",
        "print(expected)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To obtain the p-value, I performed a chi-square test for independence. The chi-square test is used to determine if there is a significant association between two categorical variables. In this case, I wanted to test if there was a significant association between the time of year and the number of new movies and TV shows added to Netflix."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I choose the chi-square test for independence as I was interested in testing for a potential association between two categorical variables."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of movies on Netflix is greater than the number of TV shows, with 5372 movies and 2398 TV shows currently available on the platform.\n",
        "\n",
        "Null hypothesis H0: The number of movies and TV shows on Netflix is not significantly different.\n",
        "\n",
        "Alternate hypothesis Ha: The number of movies on Netflix is significantly greater than the number of TV shows."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Count the number of movies and TV shows\n",
        "n_movies = df[df['type'] == 'Movie'].count()['type']\n",
        "n_tv_shows = df[df['type'] == 'TV Show'].count()['type']\n",
        "\n",
        "# Set counts and sample sizes for the z-test\n",
        "counts = [n_movies, n_tv_shows]\n",
        "nobs = [len(df), len(df)]\n",
        "\n",
        "# Print counts and sample sizes\n",
        "print('Counts:', counts)\n",
        "print('Sample sizes:', nobs)\n",
        "\n",
        "# Perform a z-test assuming equal proportions\n",
        "z_stat, p_val = sm.stats.proportions_ztest(counts, nobs, value=0, alternative='larger')\n",
        "\n",
        "# Print z-test results\n",
        "print('z-statistic:', z_stat)\n",
        "print('p-value:', p_val)\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a two-sample z-test for proportions to obtain the p-value."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the two-sample z-test for proportions to compare the number of movies and TV shows on Netflix because the data consists of two categorical variables"
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Already done with this step earlier"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "df.head()"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column called 'tags' in the DataFrame 'df'\n",
        "# The purpose of this column is to store text data that will be used for model building\n",
        "# The text data consists of the 'description', 'rating', 'country', 'listed_in', and 'cast' columns\n",
        "df['tags'] = df['description'] + ' ' + df['rating'] + ' ' + df['country'] + ' ' + df['listed_in'] + ' ' + df['cast']"
      ],
      "metadata": {
        "id": "B4zZY6DbRlHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tags']"
      ],
      "metadata": {
        "id": "nuWvcxAvx32b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['tags'][0])"
      ],
      "metadata": {
        "id": "FyysvmhmRpAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'tags' is a valid column in your DataFrame\n",
        "def to_lower(x):\n",
        "    return x.lower()\n",
        "\n",
        "# Apply the to_lower() function to the 'tags' column of the DataFrame\n",
        "df['tags'] = df['tags'].apply(to_lower)\n",
        "\n",
        "# Cross-check the result for the function created\n",
        "print(df['tags'][0])\n"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "# Define a function to remove punctuation from text\n",
        "import string\n",
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "    # Replace each punctuation mark with no space, effectively deleting it from the text\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    text_without_punct = text.translate(translator)\n",
        "\n",
        "    # Return the text with punctuation removed\n",
        "    return text_without_punct\n",
        "\n",
        "# Apply the remove_punctuation function to the 'tags' column of the DataFrame\n",
        "df['tags'] = df['tags'].apply(remove_punctuation)\n",
        "\n",
        "# Print the first 'tags' value to cross-check that the function worked as expected\n",
        "print(df['tags'][0])\n"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "df['tags'] = df['tags'].str.replace(r'\\w*\\d\\w*', '', regex=True)\n",
        "# remove words and digits containing digits\n",
        "\n",
        "# cross checking our result for the function created\n",
        "print(df['tags'][0])"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download the stopwords dataset if you haven't done so already\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Set up the stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stop_words(x):\n",
        "    ''' function to remove stop words'''\n",
        "    x = x.split()\n",
        "    res = ''\n",
        "    for word in x:\n",
        "        if word not in stop_words:  # Use stop_words instead of remove_stop_words\n",
        "            res += word + ' '  # Fix is here, no space before word\n",
        "    return res.strip()  # Trim any leading or trailing spaces\n",
        "\n",
        "# Cross-checking the result before and after applying the function\n",
        "print('Before:')\n",
        "print(df['tags'][0])\n",
        "\n",
        "# Applying the created function\n",
        "df['tags'] = df['tags'].apply(remove_stop_words)\n",
        "\n",
        "# Cross-checking the result after applying the function\n",
        "print('After:')\n",
        "print(df['tags'][0])\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tags'] = df['tags'].str.strip()\n",
        "# cross checking our result for the function created\n",
        "\n",
        "print(df['tags'][0])"
      ],
      "metadata": {
        "id": "-naGckFcT4A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#not required"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization not required"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snowballstemmer\n",
        "from snowballstemmer import stemmer"
      ],
      "metadata": {
        "id": "-O3x0OWLUPPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Assuming you've already defined your DataFrame df\n",
        "\n",
        "# Create an object of Snowball Stemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "# Define the stemming function\n",
        "def stemming(text):\n",
        "    '''a function which stems each word in the given text'''\n",
        "    text = [stemmer.stem(word) for word in text.split()]\n",
        "    return \" \".join(text)\n",
        "\n",
        "# Apply stemming to the 'tags' column\n",
        "df['tags'] = df['tags'].apply(stemming)\n",
        "\n",
        "# Vectorizing Text\n",
        "# Create the object of tfidf vectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english', lowercase=False, max_features=9000)\n",
        "\n",
        "# Fit the vectorizer using the text data\n",
        "tfidf.fit(df['tags'])\n",
        "\n",
        "# Collect the vocabulary items used in the vectorizer\n",
        "dictionary = tfidf.vocabulary_.items()\n"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert vector into array form for clustering\n",
        "vector = tfidf.transform(df['tags']).toarray()\n",
        "\n",
        "# summarize encoded vector\n",
        "print(vector)\n",
        "print(f'shape of vector : {vector.shape}')\n",
        "print(f'datatype : {type(vector)}')"
      ],
      "metadata": {
        "id": "Skk_hQBeUp5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# not required"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text is not required"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "ChlN_3zycvRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(random_state=32)\n",
        "pca.fit(vector)\n"
      ],
      "metadata": {
        "id": "ddjKK-3Cc-9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.title('PCA - cumulative explained variance vs number of components')\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance')\n",
        "plt.axhline(y= 0.8, color='red', linestyle='--')\n",
        "plt.axvline(x= 2500, color='green', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ytyM9b8uhZmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reducing the dimensions to 2500 using pca\n",
        "pca = PCA(n_components=2500, random_state=32)\n",
        "pca.fit(vector)"
      ],
      "metadata": {
        "id": "xnlvP7muhhON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformed features\n",
        "X = pca.transform(vector)"
      ],
      "metadata": {
        "id": "YmSgU3cehiTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Silhouette score(2-12)"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "silhouette_avg = []\n",
        "# range_n_clusters = [2,3,4,5,6,7,8,9,10]\n",
        "for n_clusters in range(2, 12):\n",
        "    clusterer = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    preds = clusterer.fit_predict(X)\n",
        "    centers = clusterer.cluster_centers_\n",
        "\n",
        "    score = silhouette_score(X, preds)\n",
        "    silhouette_avg.append(score)\n",
        "    print(\"For n_clusters = {}, silhouette score is {}\".format(n_clusters, score))\n",
        "\n",
        "plt.plot(range(2,12), silhouette_avg)\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Silhouette score')\n",
        "plt.title('Silhouette analysis For Optimal k - KMeans clustering')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering the data into 10 clusters as silhouette score\n",
        "kmeans = KMeans(n_clusters=10, init='k-means++', random_state=32)\n",
        "kmeans.fit(X)"
      ],
      "metadata": {
        "id": "CktSfg6hjpJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics - distortion, Silhouette score\n",
        "kmeans_distortion = kmeans.inertia_\n",
        "kmeans_silhouette_score = silhouette_score(X, kmeans.labels_)\n",
        "print(f'Kmeans distortion = {kmeans_distortion}')\n",
        "print(f'Silhouette Score = {kmeans_silhouette_score}')"
      ],
      "metadata": {
        "id": "_1T-NEaZjvh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# updating kmeans cluster number attribute\n",
        "df['kmeans_cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "j7OxzQIjkvTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of movies and tv shows in each cluster\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.countplot(x='kmeans_cluster',data=df, hue='type')\n",
        "plt.title('Number of movies and TV shows in each cluster - Kmeans Clustering')\n",
        "plt.xlabel('Kmeans Cluster')\n",
        "plt.ylabel('Count')\n",
        "for p in plt.gca().patches:\n",
        "    plt.gca().annotate(f'\\n{p.get_height()}', (p.get_x()+0.4, p.get_height()), ha='center', rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O2lpPowJk0Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating Cluster Using Dendogram**"
      ],
      "metadata": {
        "id": "lyOeDIOnk8hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(13,8))\n",
        "dendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Netflix Shows')\n",
        "plt.ylabel('Euclidean Distances')\n",
        "plt.axhline(y= 5, color='r', linestyle='--')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HCjzZRcfk7kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**With threshold 5.5 we can make 5 clusters**"
      ],
      "metadata": {
        "id": "oUIp_xqWv-pM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances\n"
      ],
      "metadata": {
        "id": "hrQqDMDIvy3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting hierarchical clustering model\n",
        "hierarchical = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')\n",
        "clusters = hierarchical.fit_predict(X)\n",
        "# Adding a hierarchical cluster number attribute\n",
        "df['hierarchical_cluster'] = hierarchical.labels_\n"
      ],
      "metadata": {
        "id": "7TVVUgwgwC_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,9))\n",
        "sns.countplot(x='hierarchical_cluster',data=df, hue='type')\n",
        "plt.title('Number of movies and TV shows in each cluster - hierarchical cluster')\n",
        "plt.xlabel('hierarchical clusters')\n",
        "plt.ylabel('Count')\n",
        "for p in plt.gca().patches:\n",
        "    plt.gca().annotate(f'\\n{p.get_height()}', (p.get_x()+0.4, p.get_height()), ha='center', rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aYNiOwtJxO1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Recommandation system"
      ],
      "metadata": {
        "id": "KEhQgIOG7wnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining new dataframe for building recommandation system\n",
        "recommender_df = df.copy()\n",
        "\n",
        "# reseting index\n",
        "recommender_df.reset_index(inplace=True)\n",
        "\n",
        "# dropping show-id and index column\n",
        "recommender_df = recommender_df.drop(columns=['index', 'show_id'])"
      ],
      "metadata": {
        "id": "gv9CsfTjxQwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend(movie, sim, output_name):\n",
        "    '''\n",
        "    This function recommends top 5 movies similar to the input movie based on their similarity scores.\n",
        "    '''\n",
        "    # Display the input movie name\n",
        "    print('--'*30)\n",
        "    print(f'recommendations based on {output_name}')\n",
        "    print('--'*30)\n",
        "    print(f\"Since you liked {movie}, you may also like: \\n\")\n",
        "\n",
        "    # Find the index position of the input movie\n",
        "    index = recommender_df[recommender_df['title'] == movie].index[0]\n",
        "\n",
        "    # Sort the movies based on similarity score to find distances from recommended movies\n",
        "    distances = sorted(list(enumerate(sim[index])), reverse=True, key=lambda x:x[1])\n",
        "\n",
        "    # List the top 5 recommended movies\n",
        "    for i in distances[1:6]:\n",
        "        print(df.iloc[i[0]].title)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "id": "H3wxC0quzefP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate cosine similarity on transformed array independent features created from tags(cluster) column after performing PCA for dimenssionality reduction.\n",
        "# setting cos_similarity\n",
        "cos_similarity = cosine_similarity(X)\n",
        "\n",
        "# setting linear_kernel\n",
        "lin_similarity = linear_kernel(X)\n",
        "\n",
        "# setting rbf_kernel\n",
        "rbf_similarity = rbf_kernel(X)\n",
        "\n",
        "#setting sigmoid_kernel\n",
        "sigmoid_similarity = sigmoid_kernel(X)\n",
        "\n",
        "# setting polynomial_kernel\n",
        "polynomial_similarity = polynomial_kernel(X)\n",
        "\n",
        "# setting laplacian_kernel\n",
        "# laplacian_similarity = laplacian_kernel(X) # commenting out as it is taking lot of time.\n",
        "\n",
        "# setting chi2_kernel\n",
        "# chi2_similarity = chi2_kernel(X) # not suitable for the given scenario"
      ],
      "metadata": {
        "id": "imlOzgTozmy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # The below code can be uncommented to get the details and test the recommender\n",
        "# # getting sample of Indian movies\n",
        "# df_india = df.loc[df['country'] == 'India']\n",
        "# df_india.title.sample(20)\n",
        "\n",
        "# getting recommendations for the movie\n",
        "recommend('Welcome', cos_similarity, 'Cosine similarity')\n",
        "recommend('Welcome', lin_similarity,'linear kernel')\n",
        "recommend('Welcome', rbf_similarity,'radial basis function (RBF) kernel')\n",
        "recommend('Welcome', sigmoid_similarity,'sigmoid kernel')\n",
        "recommend('Welcome', polynomial_similarity,' polynomial kernel')\n",
        "# recommend('Welcome', laplacian_similarity)\n",
        "# recommend('Welcome', chi2_similarity)\n"
      ],
      "metadata": {
        "id": "Vum4mWK8zx5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "dir_path = '/content/drive/MyDrive/My_new_numpy'\n",
        "\n",
        "df_export = dir_path + 'recommender_df.csv'\n",
        "X_export = dir_path + 'X.csv'\n",
        "# Create a DataFrame from the transformed data\n",
        "X_to_export = pd.DataFrame(X)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "X_to_export.to_csv('X_export', index=False)\n",
        "recommender_df.to_csv('df_export', index=False)"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the transformed data from a CSV file\n",
        "recom_df = pd.read_csv('df_export')\n",
        "X_import = pd.read_csv('X_export')\n",
        "\n",
        "# Convert the DataFrame to a NumPy array\n",
        "X_imported = X_import.values"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our aim was to cluster shows for a content-based recommender system recommending 5 shows to users based on viewing history. Starting with 7787 records and 11 attributes, we focused on Netflix's content. Analysis revealed more movies than TV shows, with a growing U.S. collection. We selected six attributes for clustering, transformed into a 9000-feature TFIDF vector, and reduced dimensions to 2500 using PCA. K-Means and Agglomerative clustering resulted in 7 and 5 optimal clusters, respectively. We built a content-based recommender system using cosine similarity, offering personalized suggestions by analyzing the user's watched shows, presenting 5 top-notch recommendations to explore."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}